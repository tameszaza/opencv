{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0126f144-a3f7-4b8a-8396-aac3443b3253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "# Open the camera\n",
    "def detect(img, cascade):\n",
    "    rects = cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=4, minSize=(30, 30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    if len(rects) == 0:\n",
    "        return []\n",
    "    rects[:,2:] += rects[:,:2]\n",
    "    return rects\n",
    "\n",
    "def draw_rects(img, rects, color):\n",
    "    for x1, y1, x2, y2 in rects:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Cannot read frame\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for processing\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "\n",
    "    # Detect faces\n",
    "    rects = detect(gray, face_cascade) #face\n",
    "    draw_rects(frame, rects, (0, 255, 0))\n",
    "\n",
    "    #draw eye \n",
    "    if not eye_cascade.empty():\n",
    "        for x1, y1, x2, y2 in rects: #face\n",
    "            roi = gray[y1:y2, x1:x2]\n",
    "            vis_roi = frame[y1:y2, x1:x2]\n",
    "            subrects = detect(roi.copy(), eye_cascade)\n",
    "            draw_rects(vis_roi, subrects, (255, 0, 0))\n",
    "    # Display the frame\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # Press 'q' to exit the program\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3696b9dd-d65a-489e-ad9f-e13b472bd26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "# Load the pre-trained Haar Cascade for cat face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "image = cv2.imread('people.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(20, 20))\n",
    "for (i, (x, y, w, h)) in enumerate(faces):\n",
    "\tcv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\tcv2.putText(image, \"face #{}\".format(i + 1), (x, y - 10),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 0, 255), 2)\n",
    "cv2.imshow(\"Faces\", image)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c0c5ed-8a40-444f-8522-d69721059822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open the video file\n",
    "video_capture = cv2.VideoCapture('people1.mp4')\n",
    "\n",
    "while video_capture.isOpened():\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Break the loop if no more frames are available\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=4, minSize=(30, 30))\n",
    "\n",
    "    # Draw rectangles around the faces and add labels\n",
    "    for (i, (x, y, w, h)) in enumerate(faces):\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"face #{}\".format(i + 1), (x, y - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the frame with detected faces\n",
    "    cv2.imshow(\"Faces\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba190a1c-f06c-46e8-899f-ae52f27e22db",
   "metadata": {},
   "source": [
    "# Media Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae68d2-4054-427d-bb34-30e55916c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe face detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "    while True:\n",
    "        # Read a frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Cannot read frame\")\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame with MediaPipe Face Detection\n",
    "        results = face_detection.process(frame_rgb)\n",
    "\n",
    "        # Draw face detections on the frame\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                mp_drawing.draw_detection(frame, detection)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Face Detection', frame)\n",
    "\n",
    "        # Press 'q' to exit the program\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c41086-c9fd-4dfd-a19b-d33a0bf4d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trueh\\anaconda3\\envs\\test\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe face detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "# Load the video file\n",
    "video_capture = cv2.VideoCapture('people1.mp4')\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.4) as face_detection:\n",
    "    while video_capture.isOpened():\n",
    "        # Read a frame from the video\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        # Break the loop if no more frames are available\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB (MediaPipe requires RGB input)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        results = face_detection.process(rgb_frame)\n",
    "\n",
    "        # Draw rectangles around the faces and add labels\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, _ = frame.shape\n",
    "                x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"face\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 0, 255), 2)\n",
    "\n",
    "        # Display the frame with detected faces\n",
    "        cv2.imshow(\"Faces\", frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ddb4bc-1cd4-4b14-80eb-fce09668fce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
